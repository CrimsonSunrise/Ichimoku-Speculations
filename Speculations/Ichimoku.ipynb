{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Ichimoku Clouds Speculations</h1>\n",
    "\n",
    "In this notebook, we'll be backtesting **Ichimoku Clouds** indicator in many markets and different ways.\n",
    "\n",
    "I'll not explain what is or its lore so if you're interested visit [Ichimoku Kinkō Hyō](https://en.wikipedia.org/wiki/Ichimoku_Kinkō_Hyō).\n",
    "\n",
    "As someone said **\"Don't reinvent the wheel!\"**, I will use some functions developed by other people. One of them is **Derek Banas**, who on his [Youtube channel](https://www.youtube.com/c/derekbanas) teaches how to analyze investment strategies using algorithms and many other cool things.\n",
    "\n",
    "\n",
    "## First things first\n",
    "\n",
    "So what's needed to start our speculations?\n",
    "\n",
    "We will test Ichimoku's Cloud in the following investment ways:\n",
    "\n",
    "* Forex Market\n",
    "* Crypto Market\n",
    "* Stock Market\n",
    "\n",
    "Well, we will need the following:\n",
    "\n",
    "1. Collect some ticker data from any source.\n",
    "2. Write a function to add Ichimoku's Cloud to our tickers.\n",
    "3. Write a function for each way to use Ichimoku's Cloud.\n",
    "4. Back test our functions with some parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before everything, lets import the modules that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the important modules that we're gonna use\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lets collect some tickers\n",
    "\n",
    "We will work with 1hour candles and 1day candles.\n",
    "\n",
    "Next we'll select 3 pairs of each market listed above divided into 2 timestamps to test with Ichimoku's Cloud.\n",
    "\n",
    "All the tickers was downloaded from [Forex Historical Data App](https://eatradingacademy.com/software/forex-historical-data/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the csv file and convert to a dataframe\n",
    "def csv_to_df(fileName):\n",
    "    \n",
    "    # Open the file\n",
    "    with open(fileName, newline='') as csvfile:\n",
    "    \n",
    "        Timestamp = []\n",
    "        Open = []\n",
    "        High = []\n",
    "        Low = []\n",
    "        Close = []\n",
    "        Volume = []\n",
    "        \n",
    "        # Read the csv file and parse it with a \"tab\" delimeter\n",
    "        csvText = csv.reader(csvfile, delimiter='\t', quotechar='|')\n",
    "        \n",
    "        # Iterate through the data and push the row information to our arrays\n",
    "        for row in csvText:\n",
    "            Timestamp.append(str(row[0]))\n",
    "            Open.append(float(row[1]))\n",
    "            High.append(float(row[2]))\n",
    "            Low.append(float(row[3]))\n",
    "            Close.append(float(row[4]))\n",
    "            Volume.append(int(row[5]))\n",
    "        \n",
    "        # Get the arrays and build the dataframe\n",
    "        df = pd.DataFrame({ 'Open': Open, 'High': High, 'Low': Low, 'Close': Close, 'Volume': Volume, \"Timestamp\": Timestamp })\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Creating all the dataframes we will need\n",
    "\n",
    "# Forex 1h\n",
    "eurusd_h = csv_to_df('EURUSD60.csv')\n",
    "gbpjpy_h = csv_to_df('GBPJPY60.csv')\n",
    "xauusd_h = csv_to_df('XAUUSD60.csv')\n",
    "# Forex 1d\n",
    "eurusd_d = csv_to_df('EURUSD1440.csv')\n",
    "gbpjpy_d = csv_to_df('GBPJPY1440.csv')\n",
    "xauusd_d = csv_to_df('XAUUSD1440.csv')\n",
    "\n",
    "# Crypto 1h\n",
    "btcusd_h = csv_to_df('BTCUSD60.csv')\n",
    "ethusd_h = csv_to_df('ETHUSD60.csv')\n",
    "adausd_h = csv_to_df('ADAUSDT60.csv')\n",
    "# Crypto 1d\n",
    "btcusd_d = csv_to_df('BTCUSD1440.csv')\n",
    "ethusd_d = csv_to_df('ETHUSD1440.csv')\n",
    "adausd_d = csv_to_df('ADAUSDT1440.csv')\n",
    "\n",
    "# Stocks 1h\n",
    "aapl_h = csv_to_df('AAPLUSUSD60.csv')\n",
    "nflx_h = csv_to_df('NFLXUSUSD60.csv')\n",
    "tsla_h = csv_to_df('TSLAUSUSD60.csv')\n",
    "\n",
    "# Stocks 1d\n",
    "aapl_d = csv_to_df('AAPLUSUSD1440.csv')\n",
    "nflx_d = csv_to_df('NFLXUSUSD1440.csv')\n",
    "tsla_d = csv_to_df('TSLAUSUSD1440.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Writing our Ichimoku's Cloud function\n",
    "\n",
    "The Ichimoku's Cloud indicator is a group of 5 lines:\n",
    "\n",
    "1. **Tenkan-sen**: (Conversion Line): (9-period high + 9-period low)/2))\n",
    "2. **Kijun-sen**: (Base Line): (26-period high + 26-period low)/2))\n",
    "3. **Senkou Span A**: (Leading Span A): (Conversion Line + Base Line)/2))\n",
    "4. **Senkou Span B**: (Leading Span B): (52-period high + 52-period low)/2))\n",
    "5. **Chikou Span**: (Lagging Span): Close plotted 26 periods in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to edit the dataframe and add the Ichimoku key values\n",
    "def add_Ichimoku_to_df(df):\n",
    "\n",
    "    # Conversion\n",
    "    hi_val = df['High'].rolling(window=9).max()\n",
    "    low_val = df['Low'].rolling(window=9).min()\n",
    "    df['Conversion'] = (hi_val + low_val) / 2\n",
    "\n",
    "    # Baseline\n",
    "    hi_val2 = df['High'].rolling(window=26).max()\n",
    "    low_val2 = df['Low'].rolling(window=26).min()\n",
    "    df['Baseline'] = (hi_val2 + low_val2) / 2\n",
    "\n",
    "    # Span A\n",
    "    df['SpanA'] = ((df['Conversion'] + df['Baseline']) / 2).shift(26)\n",
    "\n",
    "    # Span B\n",
    "    hi_val3 = df['High'].rolling(window=52).max()\n",
    "    low_val3 = df['Low'].rolling(window=52).min()\n",
    "    df['SpanB'] = ((hi_val3 + low_val3) / 2).shift(26)\n",
    "\n",
    "    # Lagging Span\n",
    "    df['Lagging'] = df['Close'].shift(-26)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Ichimoku's Cloud to our existing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forex 1h\n",
    "eurusd_h_ichimoku = add_Ichimoku_to_df(eurusd_h)\n",
    "gbpjpy_h_ichimoku = add_Ichimoku_to_df(gbpjpy_h)\n",
    "xauusd_h_ichimoku = add_Ichimoku_to_df(xauusd_h)\n",
    "# Forex 1d\n",
    "eurusd_d_ichimoku = add_Ichimoku_to_df(eurusd_d)\n",
    "gbpjpy_d_ichimoku = add_Ichimoku_to_df(gbpjpy_d)\n",
    "xauusd_d_ichimoku = add_Ichimoku_to_df(xauusd_d)\n",
    "\n",
    "# Crypto 1h\n",
    "btcusd_h_ichimoku = add_Ichimoku_to_df(btcusd_h)\n",
    "ethusd_h_ichimoku = add_Ichimoku_to_df(ethusd_h)\n",
    "adausd_h_ichimoku = add_Ichimoku_to_df(adausd_h)\n",
    "# Crypto 1d\n",
    "btcusd_d_ichimoku = add_Ichimoku_to_df(btcusd_d)\n",
    "ethusd_d_ichimoku = add_Ichimoku_to_df(ethusd_d)\n",
    "adausd_d_ichimoku = add_Ichimoku_to_df(adausd_d)\n",
    "\n",
    "# Stocks 1h\n",
    "aapl_h_ichimoku = add_Ichimoku_to_df(aapl_h)\n",
    "nflx_h_ichimoku = add_Ichimoku_to_df(nflx_h)\n",
    "tsla_h_ichimoku = add_Ichimoku_to_df(tsla_h)\n",
    "# Stocks 1d\n",
    "aapl_d_ichimoku = add_Ichimoku_to_df(aapl_d)\n",
    "nflx_d_ichimoku = add_Ichimoku_to_df(nflx_d)\n",
    "tsla_d_ichimoku = add_Ichimoku_to_df(tsla_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Now, we create a function for each way to use Ichimoku's Cloud\n",
    "\n",
    "Based on a study made by [Luís António Gomes Almeida](https://revistas.unal.edu.co/index.php/innovar/article/view/99677), Ichimoku's Cloud has different ways to use it. Here are some of them:\n",
    "\n",
    "* **T vs K** - Tenkan-sen versus Kijun-sen.\n",
    "\n",
    "        BUY/LONG: Tenkan-sen > Kijun-sen.\n",
    "        SELL/SHORT: Tenkan-sen < Kijun-sen.\n",
    "        \n",
    "* **T vs K vs P** - Tenkan-sen versus Kijun-sen versus Price.\n",
    "        \n",
    "        BUY/LONG: Price > Tenkan-sen > Kijun-sen.\n",
    "        SELL/SHORT: Price < Tenkan-sen < Kijun-sen.\n",
    "\n",
    "* **Ch vs P** - Chikou-span versus Price.\n",
    "\n",
    "        BUY/LONG: Chikou-span > Price.\n",
    "        SELL/SHORT: Chikou-span < Price.\n",
    "\n",
    "* **Ch vs P vs C** - Chikou-span versus Price versus Cloud.\n",
    "\n",
    "        BUY/LONG: Chikou-span > Price > Senkou-span A > Senkou-span B.\n",
    "        SELL/SHORT: Chikou-span < Price < Senkou-span A < Senkou-span B.\n",
    "\n",
    "* **5 lines and Cloud** - All the 5 lines and the Cloud.\n",
    "\n",
    "        BUY/LONG: Chikou-span > Price > Tenkan-sen > Kijun-sen > Senkou-span A > Senkou-span B.\n",
    "        SELL/SHORT: Chikou-span < Price < Tenkan-sen < Kijun-sen < Senkou-span A < Senkou-span B.\n",
    "\n",
    "\n",
    "This 5 examples shows how traders uses Ichimoku Clouds within their operations.\n",
    "Keep in mind that some of the functions listed are speculative and for testing purposes only as they have an analysis of 26 periods in the future and thus impossible to make entries when the conditions are met. Therefore, as it makes no sense to keep an imaginary result in our calculations, the functions that involve **Chikou-span** were adjusted with the 26 periods to be able to obtain \"real\" results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_k(df):\n",
    "    \n",
    "    df['label'] = np.where(df['Conversion'] > df['Baseline'], 1, 0)\n",
    "    df['group'] = df['label'].ne(df['label'].shift()).cumsum()\n",
    "    print(len(df))\n",
    "\n",
    "    df = df.groupby('group')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i, group in df:\n",
    "        result.append({\n",
    "            'operation': 'buy' if group.iloc[0]['label'] == 1 else 'sell',\n",
    "            'startTime': group.iloc[0]['Timestamp'],\n",
    "            'startValue': group.iloc[0]['Close'],\n",
    "            'endTime': group.iloc[-1]['Timestamp'],\n",
    "            'endValue': group.iloc[-1]['Close'],\n",
    "            \"result\": (group.iloc[-1]['Close'] - group.iloc[0]['Close']) if group.iloc[0]['label'] == 1 else (group.iloc[0]['Close'] - group.iloc[-1]['Close'])\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "t_k_eurusd_h = t_k(eurusd_h_ichimoku)\n",
    "t_k_gbpjpy_h = t_k(gbpjpy_h_ichimoku)\n",
    "t_k_xauusd_h = t_k(xauusd_h_ichimoku)\n",
    "t_k_eurusd_d = t_k(eurusd_d_ichimoku)\n",
    "t_k_gbpjpy_d = t_k(gbpjpy_d_ichimoku)\n",
    "t_k_xauusd_d = t_k(xauusd_d_ichimoku)\n",
    "\n",
    "t_k_btcusd_h = t_k(btcusd_h_ichimoku)\n",
    "t_k_ethusd_h = t_k(ethusd_h_ichimoku)\n",
    "t_k_adausd_h = t_k(adausd_h_ichimoku)\n",
    "t_k_btcusd_d = t_k(btcusd_d_ichimoku)\n",
    "t_k_ethusd_d = t_k(ethusd_d_ichimoku)\n",
    "t_k_adausd_d = t_k(adausd_d_ichimoku)\n",
    "\n",
    "t_k_aapl_h = t_k(aapl_h_ichimoku)\n",
    "t_k_nflx_h = t_k(nflx_h_ichimoku)\n",
    "t_k_tsla_h = t_k(tsla_h_ichimoku)\n",
    "t_k_aapl_d = t_k(aapl_d_ichimoku)\n",
    "t_k_nflx_d = t_k(nflx_d_ichimoku)\n",
    "t_k_tsla_d = t_k(tsla_d_ichimoku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T_K_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_k_p(df):\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    lastLabel = 0\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        if row['Close'] > row['Conversion'] and row['Conversion'] > row['Baseline']:\n",
    "            labels.append(1)\n",
    "            lastLabel = 1\n",
    "        elif row['Close'] < row['Conversion'] and row['Conversion'] < row['Baseline']:\n",
    "            labels.append(0)\n",
    "            lastLabel = 0\n",
    "        else:\n",
    "            labels.append(lastLabel)\n",
    "    \n",
    "    df['label'] = labels\n",
    "    \n",
    "    df['group'] = df['label'].ne(df['label'].shift()).cumsum()\n",
    "\n",
    "    df = df.groupby('group')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i, group in df:\n",
    "        result.append({\n",
    "            'operation': 'buy' if group.iloc[0]['label'] == 1 else 'sell',\n",
    "            'startTime': group.iloc[0]['Timestamp'],\n",
    "            'startValue': group.iloc[0]['Close'],\n",
    "            'endTime': group.iloc[-1]['Timestamp'],\n",
    "            'endValue': group.iloc[-1]['Close'],\n",
    "            \"result\": (group.iloc[-1]['Close'] - group.iloc[0]['Close']) if group.iloc[0]['label'] == 1 else (group.iloc[0]['Close'] - group.iloc[-1]['Close'])\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "t_k_p_eurusd_h = t_k_p(eurusd_h_ichimoku)\n",
    "t_k_p_gbpjpy_h = t_k_p(gbpjpy_h_ichimoku)\n",
    "t_k_p_xauusd_h = t_k_p(xauusd_h_ichimoku)\n",
    "t_k_p_eurusd_d = t_k_p(eurusd_d_ichimoku)\n",
    "t_k_p_gbpjpy_d = t_k_p(gbpjpy_d_ichimoku)\n",
    "t_k_p_xauusd_d = t_k_p(xauusd_d_ichimoku)\n",
    "\n",
    "t_k_p_btcusd_h = t_k_p(btcusd_h_ichimoku)\n",
    "t_k_p_ethusd_h = t_k_p(ethusd_h_ichimoku)\n",
    "t_k_p_adausd_h = t_k_p(adausd_h_ichimoku)\n",
    "t_k_p_btcusd_d = t_k_p(btcusd_d_ichimoku)\n",
    "t_k_p_ethusd_d = t_k_p(ethusd_d_ichimoku)\n",
    "t_k_p_adausd_d = t_k_p(adausd_d_ichimoku)\n",
    "\n",
    "t_k_p_aapl_h = t_k_p(aapl_h_ichimoku)\n",
    "t_k_p_nflx_h = t_k_p(nflx_h_ichimoku)\n",
    "t_k_p_tsla_h = t_k_p(tsla_h_ichimoku)\n",
    "t_k_p_aapl_d = t_k_p(aapl_d_ichimoku)\n",
    "t_k_p_nflx_d = t_k_p(nflx_d_ichimoku)\n",
    "t_k_p_tsla_d = t_k_p(tsla_d_ichimoku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ch_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_p(df):\n",
    "    \n",
    "    ndf = df.copy()\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    lastLabel = 0\n",
    "    \n",
    "    for i, candle in df.iterrows():\n",
    "        \n",
    "        if i > 26 and i < len(ndf):\n",
    "            \n",
    "            if ndf.iloc[i-26]['Lagging'] > ndf.iloc[i-26]['High']:\n",
    "                labels.append(1)\n",
    "                lastLabel = 1\n",
    "            elif ndf.iloc[i-26]['Lagging'] < ndf.iloc[i-26]['Low']:\n",
    "                labels.append(0)\n",
    "                lastLabel = 0\n",
    "            else:\n",
    "                labels.append(lastLabel)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    \n",
    "    ndf['label'] = labels\n",
    "    \n",
    "    ndf['group'] = ndf['label'].ne(ndf['label'].shift()).cumsum()\n",
    "\n",
    "    ndf = ndf.groupby('group')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for index, group in ndf:\n",
    "        result.append({\n",
    "            'operation': 'buy' if group.iloc[0]['label'] == 1 else 'sell',\n",
    "            'startTime': group.iloc[0]['Timestamp'],\n",
    "            'startValue': group.iloc[0]['Close'],\n",
    "            'endTime': group.iloc[-1]['Timestamp'],\n",
    "            'endValue': group.iloc[-1]['Close'],\n",
    "            \"result\": (group.iloc[-1]['Close'] - group.iloc[0]['Close']) if group.iloc[0]['label'] == 1 else (group.iloc[0]['Close'] - group.iloc[-1]['Close'])\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "ch_p_eurusd_h = ch_p(eurusd_h_ichimoku)\n",
    "ch_p_gbpjpy_h = ch_p(gbpjpy_h_ichimoku)\n",
    "ch_p_xauusd_h = ch_p(xauusd_h_ichimoku)\n",
    "ch_p_eurusd_d = ch_p(eurusd_d_ichimoku)\n",
    "ch_p_gbpjpy_d = ch_p(gbpjpy_d_ichimoku)\n",
    "ch_p_xauusd_d = ch_p(xauusd_d_ichimoku)\n",
    "\n",
    "ch_p_btcusd_h = ch_p(btcusd_h_ichimoku)\n",
    "ch_p_ethusd_h = ch_p(ethusd_h_ichimoku)\n",
    "ch_p_adausd_h = ch_p(adausd_h_ichimoku)\n",
    "ch_p_btcusd_d = ch_p(btcusd_d_ichimoku)\n",
    "ch_p_ethusd_d = ch_p(ethusd_d_ichimoku)\n",
    "ch_p_adausd_d = ch_p(adausd_d_ichimoku)\n",
    "\n",
    "ch_p_aapl_h = ch_p(aapl_h_ichimoku)\n",
    "ch_p_nflx_h = ch_p(nflx_h_ichimoku)\n",
    "ch_p_tsla_h = ch_p(tsla_h_ichimoku)\n",
    "ch_p_aapl_d = ch_p(aapl_d_ichimoku)\n",
    "ch_p_nflx_d = ch_p(nflx_d_ichimoku)\n",
    "ch_p_tsla_d = ch_p(tsla_d_ichimoku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ch_P_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_p_c(df):\n",
    "    \n",
    "    ndf = df.copy()\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    lastLabel = 0\n",
    "    \n",
    "    for i, row in ndf.iterrows():\n",
    "        \n",
    "        if i > 26 and i < len(ndf):\n",
    "        \n",
    "            if ndf.iloc[i-26]['Lagging'] > ndf.iloc[i-26]['Close'] and row['Close'] > row['SpanA'] and row['SpanA'] > row['SpanB']:\n",
    "                labels.append(1)\n",
    "                lastLabel = 1\n",
    "            elif ndf.iloc[i-26]['Lagging'] < ndf.iloc[i-26]['Close'] and row['Close'] < row['SpanA'] and row['SpanA'] < row['SpanB']:\n",
    "                labels.append(0)\n",
    "                lastLabel = 0\n",
    "            else:\n",
    "                labels.append(lastLabel)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    \n",
    "    ndf['label'] = labels\n",
    "    \n",
    "    ndf['group'] = ndf['label'].ne(ndf['label'].shift()).cumsum()\n",
    "\n",
    "    ndf = ndf.groupby('group')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i, group in ndf:\n",
    "        result.append({\n",
    "            'operation': 'buy' if group.iloc[0]['label'] == 1 else 'sell',\n",
    "            'startTime': group.iloc[0]['Timestamp'],\n",
    "            'startValue': group.iloc[0]['Close'],\n",
    "            'endTime': group.iloc[-1]['Timestamp'],\n",
    "            'endValue': group.iloc[-1]['Close'],\n",
    "            \"result\": (group.iloc[-1]['Close'] - group.iloc[0]['Close']) if group.iloc[0]['label'] == 1 else (group.iloc[0]['Close'] - group.iloc[-1]['Close'])\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "ch_p_c_eurusd_h = ch_p_c(eurusd_h_ichimoku)\n",
    "ch_p_c_gbpjpy_h = ch_p_c(gbpjpy_h_ichimoku)\n",
    "ch_p_c_xauusd_h = ch_p_c(xauusd_h_ichimoku)\n",
    "ch_p_c_eurusd_d = ch_p_c(eurusd_d_ichimoku)\n",
    "ch_p_c_gbpjpy_d = ch_p_c(gbpjpy_d_ichimoku)\n",
    "ch_p_c_xauusd_d = ch_p_c(xauusd_d_ichimoku)\n",
    "\n",
    "ch_p_c_btcusd_h = ch_p_c(btcusd_h_ichimoku)\n",
    "ch_p_c_ethusd_h = ch_p_c(ethusd_h_ichimoku)\n",
    "ch_p_c_adausd_h = ch_p_c(adausd_h_ichimoku)\n",
    "ch_p_c_btcusd_d = ch_p_c(btcusd_d_ichimoku)\n",
    "ch_p_c_ethusd_d = ch_p_c(ethusd_d_ichimoku)\n",
    "ch_p_c_adausd_d = ch_p_c(adausd_d_ichimoku)\n",
    "\n",
    "ch_p_c_aapl_h = ch_p_c(aapl_h_ichimoku)\n",
    "ch_p_c_nflx_h = ch_p_c(nflx_h_ichimoku)\n",
    "ch_p_c_tsla_h = ch_p_c(tsla_h_ichimoku)\n",
    "ch_p_c_aapl_d = ch_p_c(aapl_d_ichimoku)\n",
    "ch_p_c_nflx_d = ch_p_c(nflx_d_ichimoku)\n",
    "ch_p_c_tsla_d = ch_p_c(tsla_d_ichimoku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 lines and cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_l_c(df):\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    lastLabel = 0\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        if row['Lagging'] > row['Close'] and row['Close'] > row['Conversion'] and row['Conversion'] > row['Baseline'] and row['Baseline'] > row['SpanA'] and row['SpanA'] > row['SpanB']:\n",
    "            labels.append(1)\n",
    "            lastLabel = 1\n",
    "        elif row['Lagging'] < row['Close'] and row['Close'] < row['Conversion'] and row['Conversion'] < row['Baseline'] and row['Baseline'] < row['SpanA'] and row['SpanA'] < row['SpanB']:\n",
    "            labels.append(0)\n",
    "            lastLabel = 0\n",
    "        else:\n",
    "            labels.append(lastLabel)\n",
    "    \n",
    "    df['label'] = labels\n",
    "    \n",
    "    df['group'] = df['label'].ne(df['label'].shift()).cumsum()\n",
    "\n",
    "    df = df.groupby('group')\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i, group in df:\n",
    "        result.append({\n",
    "            'operation': 'buy' if group.iloc[0]['label'] == 1 else 'sell',\n",
    "            'startTime': group.iloc[0]['Timestamp'],\n",
    "            'startValue': group.iloc[0]['Close'],\n",
    "            'endTime': group.iloc[-1]['Timestamp'],\n",
    "            'endValue': group.iloc[-1]['Close'],\n",
    "            \"result\": (group.iloc[-1]['Close'] - group.iloc[0]['Close']) if group.iloc[0]['label'] == 1 else (group.iloc[0]['Close'] - group.iloc[-1]['Close'])\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "five_l_c_eurusd_h = five_l_c(eurusd_h_ichimoku)\n",
    "five_l_c_gbpjpy_h = five_l_c(gbpjpy_h_ichimoku)\n",
    "five_l_c_xauusd_h = five_l_c(xauusd_h_ichimoku)\n",
    "five_l_c_eurusd_d = five_l_c(eurusd_d_ichimoku)\n",
    "five_l_c_gbpjpy_d = five_l_c(gbpjpy_d_ichimoku)\n",
    "five_l_c_xauusd_d = five_l_c(xauusd_d_ichimoku)\n",
    "\n",
    "five_l_c_btcusd_h = five_l_c(btcusd_h_ichimoku)\n",
    "five_l_c_ethusd_h = five_l_c(ethusd_h_ichimoku)\n",
    "five_l_c_adausd_h = five_l_c(adausd_h_ichimoku)\n",
    "five_l_c_btcusd_d = five_l_c(btcusd_d_ichimoku)\n",
    "five_l_c_ethusd_d = five_l_c(ethusd_d_ichimoku)\n",
    "five_l_c_adausd_d = five_l_c(adausd_d_ichimoku)\n",
    "\n",
    "five_l_c_aapl_h = five_l_c(aapl_h_ichimoku)\n",
    "five_l_c_nflx_h = five_l_c(nflx_h_ichimoku)\n",
    "five_l_c_tsla_h = five_l_c(tsla_h_ichimoku)\n",
    "five_l_c_aapl_d = five_l_c(aapl_d_ichimoku)\n",
    "five_l_c_nflx_d = five_l_c(nflx_d_ichimoku)\n",
    "five_l_c_tsla_d = five_l_c(tsla_d_ichimoku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The speculations\n",
    "\n",
    "Now, before we test the Ichimoku's Cloud using the functions we wrote, let's first visualize some values.\n",
    "\n",
    "As some of you know, payouts are based on the price change between trades, so lets write some code to visualize the price change for our functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prices(strategies):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        price = 0\n",
    "        for row in strategy:\n",
    "            if row['operation']:\n",
    "            \n",
    "                if row['operation'] == 'sell':\n",
    "                    price += row['startValue'] - row['endValue']\n",
    "                else:\n",
    "                    price += row['endValue'] - row['startValue']\n",
    "                    \n",
    "            result.append(price)\n",
    "    \n",
    "    return result\n",
    "\n",
    "eurusd_h_prices = calculate_prices([t_k_eurusd_h, t_k_p_eurusd_h, ch_p_eurusd_h, ch_p_c_eurusd_h[0], five_l_c_eurusd_h])\n",
    "gbpjpy_h_prices = calculate_prices([t_k_gbpjpy_h, t_k_p_gbpjpy_h, ch_p_gbpjpy_h, ch_p_c_gbpjpy_h[0], five_l_c_gbpjpy_h])\n",
    "xauusd_h_prices = calculate_prices([t_k_xauusd_h, t_k_p_xauusd_h, ch_p_xauusd_h, ch_p_c_xauusd_h[0], five_l_c_xauusd_h])\n",
    "eurusd_d_prices = calculate_prices([t_k_eurusd_d, t_k_p_eurusd_d, ch_p_eurusd_d, ch_p_c_eurusd_d[0], five_l_c_eurusd_d])\n",
    "gbpjpy_d_prices = calculate_prices([t_k_gbpjpy_d, t_k_p_gbpjpy_d, ch_p_gbpjpy_d, ch_p_c_gbpjpy_d[0], five_l_c_gbpjpy_d])\n",
    "xauusd_d_prices = calculate_prices([t_k_xauusd_d, t_k_p_xauusd_d, ch_p_xauusd_d, ch_p_c_xauusd_d[0], five_l_c_xauusd_d])\n",
    "\n",
    "btcusd_h_prices = calculate_prices([t_k_btcusd_h, t_k_p_btcusd_h, ch_p_btcusd_h, ch_p_c_btcusd_h[0], five_l_c_btcusd_h])\n",
    "ethusd_h_prices = calculate_prices([t_k_ethusd_h, t_k_p_ethusd_h, ch_p_ethusd_h, ch_p_c_ethusd_h[0], five_l_c_ethusd_h])\n",
    "adausd_h_prices = calculate_prices([t_k_adausd_h, t_k_p_adausd_h, ch_p_adausd_h, ch_p_c_adausd_h[0], five_l_c_adausd_h])\n",
    "btcusd_d_prices = calculate_prices([t_k_btcusd_d, t_k_p_btcusd_d, ch_p_btcusd_d, ch_p_c_btcusd_d[0], five_l_c_btcusd_d])\n",
    "ethusd_d_prices = calculate_prices([t_k_ethusd_d, t_k_p_ethusd_d, ch_p_ethusd_d, ch_p_c_ethusd_d[0], five_l_c_ethusd_d])\n",
    "adausd_d_prices = calculate_prices([t_k_adausd_d, t_k_p_adausd_d, ch_p_adausd_d, ch_p_c_adausd_d[0], five_l_c_adausd_d])\n",
    "\n",
    "aapl_h_prices = calculate_prices([t_k_aapl_h, t_k_p_aapl_h, ch_p_aapl_h, ch_p_c_aapl_h[0], five_l_c_aapl_h])\n",
    "nflx_h_prices = calculate_prices([t_k_nflx_h, t_k_p_nflx_h, ch_p_nflx_h, ch_p_c_nflx_h[0], five_l_c_nflx_h])\n",
    "tsla_h_prices = calculate_prices([t_k_tsla_h, t_k_p_tsla_h, ch_p_tsla_h, ch_p_c_tsla_h[0], five_l_c_tsla_h])\n",
    "aapl_d_prices = calculate_prices([t_k_aapl_d, t_k_p_aapl_d, ch_p_aapl_d, ch_p_c_aapl_d[0], five_l_c_aapl_d])\n",
    "nflx_d_prices = calculate_prices([t_k_nflx_d, t_k_p_nflx_d, ch_p_nflx_d, ch_p_c_nflx_d[0], five_l_c_nflx_d])\n",
    "tsla_d_prices = calculate_prices([t_k_tsla_d, t_k_p_tsla_d, ch_p_tsla_d, ch_p_c_tsla_d[0], five_l_c_tsla_d])\n",
    "\n",
    "strategies = ['T_K', 'T_K_P', 'Ch_P', 'Ch_P_C', 'five_l_c']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=eurusd_h_prices,\n",
    "    name='EURUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=gbpjpy_h_prices,\n",
    "    name='GBPJPY',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=xauusd_h_prices,\n",
    "    name='XAUUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=btcusd_h_prices,\n",
    "    name='BTCUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=ethusd_h_prices,\n",
    "    name='ETHUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=adausd_h_prices,\n",
    "    name='ADAUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=aapl_h_prices,\n",
    "    name='AAPL',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=nflx_h_prices,\n",
    "    name='NFLX',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=tsla_h_prices,\n",
    "    name='TSLA',\n",
    "))\n",
    "\n",
    "# Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "fig.update_layout(barmode='group', xaxis_tickangle=0, title='1h Data', height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = ['T_K', 'T_K_P', 'Ch_P', 'Ch_P_C', 'five_l_c']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=eurusd_d_prices,\n",
    "    name='EURUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=gbpjpy_d_prices,\n",
    "    name='GBPJPY',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=xauusd_d_prices,\n",
    "    name='XAUUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=btcusd_d_prices,\n",
    "    name='BTCUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=ethusd_d_prices,\n",
    "    name='ETHUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=adausd_d_prices,\n",
    "    name='ADAUSD',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=aapl_d_prices,\n",
    "    name='AAPL',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=nflx_d_prices,\n",
    "    name='NFLX',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=strategies,\n",
    "    y=tsla_d_prices,\n",
    "    name='TSLA',\n",
    "))\n",
    "\n",
    "# Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "fig.update_layout(barmode='group', xaxis_tickangle=0, title='1d Data', height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_timeline(strategies):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        strategy_array = [[], []]\n",
    "        lastPrice = 0\n",
    "        for row in strategy:\n",
    "            if row['operation'] == 'sell':\n",
    "                lastPrice += row['startValue'] - row['endValue']\n",
    "                strategy_array[0].append(row['endTime'])\n",
    "                strategy_array[1].append(lastPrice)\n",
    "            else:\n",
    "                lastPrice += row['endValue'] - row['startValue']\n",
    "                strategy_array[0].append(row['endTime'])\n",
    "                strategy_array[1].append(lastPrice)\n",
    "        result.append(strategy_array)\n",
    "    \n",
    "    return result\n",
    "\n",
    "eurusd_h_timeline = calculate_timeline([t_k_eurusd_h, t_k_p_eurusd_h, ch_p_eurusd_h, ch_p_c_eurusd_h[0], five_l_c_eurusd_h])\n",
    "gbpjpy_h_timeline = calculate_timeline([t_k_gbpjpy_h, t_k_p_gbpjpy_h, ch_p_gbpjpy_h, ch_p_c_gbpjpy_h[0], five_l_c_gbpjpy_h])\n",
    "xauusd_h_timeline = calculate_timeline([t_k_xauusd_h, t_k_p_xauusd_h, ch_p_xauusd_h, ch_p_c_xauusd_h[0], five_l_c_xauusd_h])\n",
    "eurusd_d_timeline = calculate_timeline([t_k_eurusd_d, t_k_p_eurusd_d, ch_p_eurusd_d, ch_p_c_eurusd_d[0], five_l_c_eurusd_d])\n",
    "gbpjpy_d_timeline = calculate_timeline([t_k_gbpjpy_d, t_k_p_gbpjpy_d, ch_p_gbpjpy_d, ch_p_c_gbpjpy_d[0], five_l_c_gbpjpy_d])\n",
    "xauusd_d_timeline = calculate_timeline([t_k_xauusd_d, t_k_p_xauusd_d, ch_p_xauusd_d, ch_p_c_xauusd_d[0], five_l_c_xauusd_d])\n",
    "\n",
    "btcusd_h_timeline = calculate_timeline([t_k_btcusd_h, t_k_p_btcusd_h, ch_p_btcusd_h, ch_p_c_btcusd_h[0], five_l_c_btcusd_h])\n",
    "ethusd_h_timeline = calculate_timeline([t_k_ethusd_h, t_k_p_ethusd_h, ch_p_ethusd_h, ch_p_c_ethusd_h[0], five_l_c_ethusd_h])\n",
    "adausd_h_timeline = calculate_timeline([t_k_adausd_h, t_k_p_adausd_h, ch_p_adausd_h, ch_p_c_adausd_h[0], five_l_c_adausd_h])\n",
    "btcusd_d_timeline = calculate_timeline([t_k_btcusd_d, t_k_p_btcusd_d, ch_p_btcusd_d, ch_p_c_btcusd_d[0], five_l_c_btcusd_d])\n",
    "ethusd_d_timeline = calculate_timeline([t_k_ethusd_d, t_k_p_ethusd_d, ch_p_ethusd_d, ch_p_c_ethusd_d[0], five_l_c_ethusd_d])\n",
    "adausd_d_timeline = calculate_timeline([t_k_adausd_d, t_k_p_adausd_d, ch_p_adausd_d, ch_p_c_adausd_d[0], five_l_c_adausd_d])\n",
    "\n",
    "aapl_h_timeline = calculate_timeline([t_k_aapl_h, t_k_p_aapl_h, ch_p_aapl_h, ch_p_c_aapl_h[0], five_l_c_aapl_h])\n",
    "nflx_h_timeline = calculate_timeline([t_k_nflx_h, t_k_p_nflx_h, ch_p_nflx_h, ch_p_c_nflx_h[0], five_l_c_nflx_h])\n",
    "tsla_h_timeline = calculate_timeline([t_k_tsla_h, t_k_p_tsla_h, ch_p_tsla_h, ch_p_c_tsla_h[0], five_l_c_tsla_h])\n",
    "aapl_d_timeline = calculate_timeline([t_k_aapl_d, t_k_p_aapl_d, ch_p_aapl_d, ch_p_c_aapl_d[0], five_l_c_aapl_d])\n",
    "nflx_d_timeline = calculate_timeline([t_k_nflx_d, t_k_p_nflx_d, ch_p_nflx_d, ch_p_c_nflx_d[0], five_l_c_nflx_d])\n",
    "tsla_d_timeline = calculate_timeline([t_k_tsla_d, t_k_p_tsla_d, ch_p_tsla_d, ch_p_c_tsla_d[0], five_l_c_tsla_d])\n",
    "\n",
    "\n",
    "def show_timeline_plot(timeline, title):\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=timeline[0][0], y=timeline[0][1], name=\"T_K (\" + str(len(timeline[0][1])) + \")\")\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=timeline[1][0], y=timeline[1][1], name=\"T_K_P (\" + str(len(timeline[1][1])) + \")\")\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=timeline[2][0], y=timeline[2][1], name=\"Ch_P (\" + str(len(timeline[2][1])) + \")\")\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=timeline[3][0], y=timeline[3][1], name=\"Ch_P_C (\" + str(len(timeline[3][1])) + \")\")\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=timeline[4][0], y=timeline[4][1], name=\"Five_l_c (\" + str(len(timeline[4][1])) + \")\")\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=title,\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(constrain=\"range\")\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "show_timeline_plot(eurusd_h_timeline, \"EURUSD 1h\")\n",
    "show_timeline_plot(eurusd_d_timeline, \"EURUSD 1d\")\n",
    "show_timeline_plot(gbpjpy_h_timeline, \"GBPJPY 1h\")\n",
    "show_timeline_plot(gbpjpy_d_timeline, \"GBPJPY 1d\")\n",
    "show_timeline_plot(xauusd_h_timeline, \"XAUUSD 1h\")\n",
    "show_timeline_plot(xauusd_d_timeline, \"XAUUSD 1d\")\n",
    "\n",
    "show_timeline_plot(btcusd_h_timeline, \"BTCUSD 1h\")\n",
    "show_timeline_plot(btcusd_d_timeline, \"BTCUSD 1d\")\n",
    "show_timeline_plot(ethusd_h_timeline, \"ETHUSD 1h\")\n",
    "show_timeline_plot(ethusd_d_timeline, \"ETHUSD 1d\")\n",
    "show_timeline_plot(adausd_h_timeline, \"ADAUSD 1h\")\n",
    "show_timeline_plot(adausd_d_timeline, \"ADAUSD 1d\")\n",
    "\n",
    "show_timeline_plot(aapl_h_timeline, \"AAPL 1h\")\n",
    "show_timeline_plot(aapl_d_timeline, \"AAPL 1d\")\n",
    "show_timeline_plot(nflx_h_timeline, \"NFLX 1h\")\n",
    "show_timeline_plot(nflx_d_timeline, \"NFLX 1d\")\n",
    "show_timeline_plot(tsla_h_timeline, \"TSLA 1h\")\n",
    "show_timeline_plot(tsla_d_timeline, \"TSLA 1d\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "403a2ad6e576b75ccc1cbe0db7da4782c2da8f985a9ae0627b4737d54f6b8fcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
